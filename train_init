import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import torch
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from tqdm import tqdm
from data_loading import load_data_from_directories, preprocess_data
from model import ZulfRNNModel, weighted_mse_loss
from utils import simulate_zulf_spectrum, reshape_data_for_rnn

###run using 'python train.py'


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

if __name__ == "__main__":
    root_dir = r'C:\Users\agsse\Downloads\Supplemantary_Data\Data supplemantary\CuSO4 solutions\CuSO4_solutions_vacummed'
    sub_dirs = ['0_microM','200_microM','400_microM','600_microM','800_microM','1000_microM']  
    

    if os.path.exists('X_train.npy') and os.path.exists('y_train.npy') and \
       os.path.exists('X_test.npy') and os.path.exists('y_test.npy'):
        print("Loading preprocessed data from disk...")
        X_train_np = np.load('X_train.npy')
        y_train_np = np.load('y_train.npy')
        X_test_np = np.load('X_test.npy')
        y_test_np = np.load('y_test.npy')
        print(f"Loaded preprocessed data shapes: X_train={X_train_np.shape}, y_train={y_train_np.shape}, X_test={X_test_np.shape}, y_test={y_test_np.shape}")
    else:
        print("Loading data from directories...")
        try:
            data = load_data_from_directories(root_dir, sub_dirs, seq_length=1000, min_lines=10000)
            print(f"Loaded data shape: {data.shape}")
        except ValueError as e:
            print(e)
            exit(1)

        print("Preprocessing data...")
        try:
            data_preprocessed = preprocess_data(data)
            print(f"Preprocessed data shape: {data_preprocessed.shape}")
        except ValueError as e:
            print(e)
            exit(1)

        print("Simulating ZULF spectra...")
        j_couplings = np.random.uniform(1, 10, size=(data_preprocessed.shape[0], 3)) 
        _, spectra = simulate_zulf_spectrum(j_couplings, num_points=1000)
        print(f"Spectra shape: {spectra.shape}")

        print("Reshaping data for RNN...")
        X_rnn, y_rnn = reshape_data_for_rnn(j_couplings, spectra, freq_points=1000)
        print(f"Reshaped X shape: {X_rnn.shape}, y shape: {y_rnn.shape}")

        X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(
            X_rnn, y_rnn, test_size=0.2, random_state=42
        )

        print("Saving preprocessed data to disk...")
        np.save('X_train.npy', X_train_np)
        np.save('y_train.npy', y_train_np)
        np.save('X_test.npy', X_test_np)
        np.save('y_test.npy', y_test_np)

    X_train = torch.tensor(X_train_np, dtype=torch.float32) 
    y_train = torch.tensor(y_train_np, dtype=torch.float32)  
    X_test = torch.tensor(X_test_np, dtype=torch.float32)    
    y_test = torch.tensor(y_test_np, dtype=torch.float32)    

    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)

    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True
    )
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True
    )

    model = ZulfRNNModel(input_dim=4, hidden_dim=64, num_layers=1).to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

    num_epochs = 5
    print("\nStarting training...")

    for epoch in range(num_epochs):
        model.train()
        
        epoch_loss = 0.0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{num_epochs}", leave=False)

        for batch_X, batch_y in progress_bar:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)  
            optimizer.zero_grad()

            pred_y = model(batch_X)

            loss = weighted_mse_loss(pred_y, batch_y, weight=10.0)

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

            progress_bar.set_postfix(loss=f"{loss.item():.6f}")

        epoch_loss /= len(train_loader)
        print(f"Epoch [{epoch + 1}/{num_epochs}] - Avg Loss: {epoch_loss:.6f}")

        model.eval()  
        val_loss = 0.0
        with torch.no_grad():  
            for batch_X, batch_y in test_loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)
                pred_y = model(batch_X)
                val_loss += weighted_mse_loss(pred_y, batch_y).item()
        val_loss /= len(test_loader)
        scheduler.step(val_loss) 
        print(f"Validation Loss: {val_loss:.6f}, Learning Rate: {optimizer.param_groups[0]['lr']:.6f}")

    print("\nPlotting predictions for first 3 test samples...")
    with torch.no_grad():
        sample_X = X_test[:3].to(device)
        sample_y = y_test[:3].to(device)
        pred_y = model(sample_X).squeeze(-1)

    plt.figure(figsize=(10, 6))
    for i in range(3):
        plt.subplot(3, 1, i + 1)
        true_spectrum = sample_y[i].squeeze(-1).cpu().numpy()
        pred_spectrum = pred_y[i].cpu().numpy()

        plt.plot(true_spectrum, label='True ZULF Spectrum')
        plt.plot(pred_spectrum, label='Predicted ZULF Spectrum', linestyle='--')
        plt.legend()
        plt.xlabel('Frequency Index')
        plt.ylabel('Intensity')

    plt.tight_layout()
    plt.show()
    print("Done.")
